<!doctype html>
<html lang="fr">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>QCM — Hands-On Machine Learning (Géron) — Chapitres 1–9</title>
  <style>
    :root{--bg:#0f1724;--card:#0b1220;--accent:#0ea5a0;--muted:#94a3b8;--text:#e6eef8}
    *{box-sizing:border-box}
    body{margin:0;font-family:Inter,system-ui,Roboto,'Helvetica Neue',Arial;background:linear-gradient(180deg,#071021 0%,#0b1220 100%);color:var(--text);min-height:100vh}
    .wrap{display:flex;gap:20px;padding:24px;align-items:flex-start}
    .sidebar{width:260px;padding:18px;border-radius:12px;background:rgba(255,255,255,0.02);border:1px solid rgba(255,255,255,0.03);height:calc(100vh - 48px);overflow:auto}
    .main{flex:1;max-width:980px;padding:18px;border-radius:12px;background:linear-gradient(180deg,rgba(255,255,255,0.02),rgba(255,255,255,0.01));border:1px solid rgba(255,255,255,0.03);height:calc(100vh - 48px);overflow:auto}
    h1{margin:0 0 6px;font-size:18px}
    .muted{color:var(--muted);font-size:13px}
    .chap{margin:8px 0;padding:8px;border-radius:8px;cursor:pointer}
    .chap:hover{background:rgba(255,255,255,0.01)}
    .chap.active{background:linear-gradient(90deg,rgba(14,165,160,0.12),rgba(14,165,160,0.04));border:1px solid rgba(14,165,160,0.08)}
    .q{background:rgba(255,255,255,0.02);border:1px solid rgba(255,255,255,0.03);padding:14px;border-radius:10px;margin-bottom:12px}
    .q h3{margin:0 0 8px;font-size:16px}
    .alts{display:grid;grid-template-columns:repeat(2,1fr);gap:8px}
    label.alt{display:flex;align-items:center;gap:10px;padding:10px;border-radius:8px;border:1px solid transparent;cursor:pointer}
    label.alt input{width:18px;height:18px}
    label.alt:hover{background:rgba(255,255,255,0.01)}
    .controls{display:flex;gap:10px;align-items:center;margin-top:16px}
    button{background:var(--accent);border:none;padding:10px 14px;border-radius:8px;color:#042022;font-weight:600;cursor:pointer}
    button.secondary{background:transparent;border:1px solid rgba(255,255,255,0.06);color:var(--text)}
    .results{margin-top:14px;padding:12px;border-radius:10px;background:linear-gradient(180deg,rgba(255,255,255,0.01),rgba(255,255,255,0.007));border:1px solid rgba(255,255,255,0.02)}
    footer{margin-top:18px;color:var(--muted);font-size:13px}
    @media(max-width:900px){.wrap{flex-direction:column}.sidebar{width:100%;height:auto}.main{height:auto}}
  </style>
</head>
<body>
  <div class="wrap">
    <aside class="sidebar">
      <h1>QCM — Hands-On Machine Learning</h1>
      <p class="muted">Chapitres 1 à 9 ajoutés. Clique sur un chapitre pour afficher ses questions.</p>
      <div id="chapList"></div>
      <hr style="border:none;border-top:1px solid rgba(255,255,255,0.03);margin:12px 0">
      <div class="muted">Contrôles globaux</div>
      <div style="display:flex;gap:8px;margin-top:8px">
        <button id="checkAll">Vérifier</button>
        <button class="secondary" id="resetAll">Réinitialiser</button>
      </div>
      <div style="margin-top:10px;color:var(--muted)">Progress global: <span id="globalProgress">0 / 0</span></div>
      <footer style="margin-top:18px">Source : Aurélien Géron — <em>Hands-On Machine Learning</em></footer>
    </aside>

    <main class="main">
      <div id="header">
        <h2 id="title">Chapitre 1 — The Machine Learning Landscape</h2>
        <div class="muted" id="subtitle">19 questions</div>
      </div>

      <div id="quiz"></div>

      <div class="controls">
        <button id="check">Vérifier ce chapitre</button>
        <button class="secondary" id="showAnswers">Afficher les réponses</button>
        <button class="secondary" id="reset">Réinitialiser</button>
        <div style="margin-left:auto;color:var(--muted)">Progress: <span id="progress">0 / 0</span></div>
      </div>

      <div class="results" id="results" aria-live="polite" style="display:none"></div>
    </main>
  </div>

  <script>
    // Questions grouped by chapter (chapitres 1 à 9). C'est un jeu de questions représentatif, pas exhaustif.
    const chapters = [
      {id:1, title:'The Machine Learning Landscape', desc:'19 questions', qs:[
        {q:"Quel est le principal objectif du Machine Learning ?", opts:["Maximiser la taille des datasets","Apprendre à prédire ou prendre une décision à partir de données","Remplacer tous les algorithmes classiques","Faire tourner des modèles sur GPU"], ans:1},
        {q:"Un système qui apprend à partir d'exemples plutôt qu'être explicitement programmé est :", opts:["Un programme classique","Un système ML","Un système à règles expertes","Un moteur de rendu"], ans:1},
        {q:"Le supervised learning consiste à :", opts:["Apprendre à partir de données labellisées","Trouver des patterns cachés sans labels","Générer de nouvelles données","Ne pas utiliser du tout les données"], ans:0},
        {q:"Exemple typique de supervised learning :", opts:["Clustering client","Classification d'images","Compression de données","Détection d'anomalies"], ans:1},
        {q:"Unsupervised learning = …", opts:["On connaît la cible","On ne connaît pas les labels","On entraîne toujours un réseau deep learning","On mesure la performance avec l'accuracy"], ans:1},
        {q:"Exemple typique d'unsupervised learning ?", opts:["SVM","Régression linéaire","K-Means","Random Forest"], ans:2},
        {q:"Reinforcement Learning implique :", opts:["Un agent qui apprend par essais et erreurs","Des labels fixes","Pas de rétroaction","Pas d'environnement"], ans:0},
        {q:"Parmi les problématiques ML, lesquelles sont du supervised ?", opts:["Regression","Classification","Clustering","A et B seulement"], ans:3},
        {q:"Le batch learning signifie :", opts:["On entraîne le modèle une seule fois","On entraîne en continu","Le modèle se met à jour à chaque nouvelle donnée","On ne peut pas l'utiliser en industrie"], ans:0},
        {q:"Le online learning est utile quand :", opts:["Les données arrivent lentement","Les données arrivent en continu","On a besoin de recompiler le modèle à chaque fois","On veut absolument éviter l'adaptation"], ans:1},
        {q:"Un modèle sous-apprend quand :", opts:["Il mémorise tout","Il généralise très bien","Il est trop simple et performe mal","Il sur-ajuste"], ans:2},
        {q:"Le sur-apprentissage (overfitting) se traduit par :", opts:["Haute performance sur test","Haute performance sur train","Performance équilibrée train/test","Modèle trop simple"], ans:1},
        {q:"Quelle technique réduit l'overfitting ?", opts:["Plus de features inutiles","Complexifier le modèle","Utiliser régularisation / plus de data","Rien"], ans:2},
        {q:"Dans un pipeline ML réel, la tâche la plus coûteuse est souvent :", opts:["Le choix de l'algorithme","Le feature engineering et nettoyage des données","L'inférence","La visualisation"], ans:1},
        {q:"Un modèle ML n'est utile que si :", opts:["Il est profond","Il généralise sur données jamais vues","On peut l'implémenter en C","Il utilise un GPU"], ans:1},
        {q:"La différence principale entre instance-based et model-based learning est :", opts:["Instance-based construit un modèle global","Instance-based apprend les exemples et compare","Model-based stocke tous les exemples","Aucune différence"], ans:1},
        {q:"La détection d'anomalies est typiquement une tâche :", opts:["Supervised","Unsupervised","Reinforcement","None of the above"], ans:1},
        {q:"La réduction de dimension (PCA, t-SNE) sert à :", opts:["Augmenter le nombre de features","Simplifier les données sans trop perdre d'information","Rendre les données bruyantes","Transformer un problème supervisé en non supervisé"], ans:1},
        {q:"La validation finale d'un modèle (estimation de l'erreur de généralisation) se fait généralement sur :", opts:["Le training set","Le test set","Les hyperparamètres","Le jeu de données original sans split"], ans:1}
      ]},

      {id:2, title:'End-to-End Machine Learning Project', desc:'10 questions', qs:[
        {q:"Quel indicateur est souvent utilisé pour mesurer la performance en régression ?", opts:["Accuracy","RMSE","ROC AUC","Precision"], ans:1},
        {q:"Que signifie 'feature engineering' ?", opts:["Créer et sélectionner des caractéristiques utiles","Faire de l'optimisation GPU","Diviser le dataset","Rien"], ans:0},
        {q:"Pourquoi créer un jeu test séparé ?", opts:["Pour entraîner plus longtemps","Pour estimer l'erreur de généralisation","Pour normaliser les données","Pour visualiser"], ans:1},
        {q:"Qu'est-ce qu'une pipeline en ML ?", opts:["Une suite de transformations et d'un modèle","Un algorithme de clustering","Un type de réseau neuronal","Un format de fichier"], ans:0},
        {q:"Quel procédé sert à sélectionner les hyperparamètres ?", opts:["Cross-validation","Gradient descent","PCA","Bootstrap"], ans:0},
        {q:"Que fait GridSearchCV ?", opts:["Teste des combinaisons d'hyperparamètres par CV","Génère de nouvelles features","Fait du clustering","Mesure la vitesse"], ans:0},
        {q:"Lequel n'est pas une étape typique pour préparer les données ?", opts:["Nettoyage","Gestion des valeurs manquantes","Compilation du modèle C","Encodage des catégoriques"], ans:2},
        {q:"Quand faut-il monitorer un modèle en production ?", opts:["Jamais","En continu pour détecter dérive de données","Seulement au déploiement","Quand l'API tombe en panne"], ans:1},
        {q:"Quelle métrique choisir pour un problème d'investissement où grosses erreurs sont critiques ?", opts:["Accuracy","RMSE (pondère les grosses erreurs)","Recall","F1-score"], ans:1},
        {q:"Pourquoi utiliser des transformations (scaling) ?", opts:["Améliorer convergence des algos de gradient","Rendre le modèle plus profond","Augmenter la mémoire utilisée","Pour colorer les plots"], ans:0}
      ]},

      {id:3, title:'Classification', desc:'10 questions', qs:[
        {q:"Qu'est-ce que la matrice de confusion ?", opts:["Un graphique 3D","Un tableau vrai/faux positifs/négatifs","Une méthode de prétraitement","Un optimiseur"], ans:1},
        {q:"Precision mesure :", opts:["Vrais positifs / prédits positifs","Vrais positifs / vrais positifs+faux négatifs","Tous les positifs","La vitesse d'entraînement"], ans:0},
        {q:"Recall (rappel) mesure :", opts:["Vrais positifs / prédits positifs","Vrais positifs / vrais positifs+faux négatifs","Faux positifs / vrais positifs","La perte"], ans:1},
        {q:"Courbe ROC trace :", opts:["Precision vs Recall","TPR vs FPR","Loss vs Epoch","Accuracy vs Threshold"], ans:1},
        {q:"Pour un dataset déséquilibré, quelle métrique privilégier ?", opts:["Accuracy","Precision/Recall ou F1","Nombre de features","Taux d'apprentissage"], ans:1},
        {q:"La classification multilabel signifie :", opts:["Plusieurs classes mutuellement exclusives","Chaque instance peut avoir plusieurs labels","Label unique par instance","Régression déguisée"], ans:1},
        {q:"Softmax est utile pour :", opts:["Régulariser","Multiclass classification (probabilités)","Clustering","PCA"], ans:1},
        {q:"Que mesure l'accuracy ?", opts:["Proportion de prédictions correctes","La complexité du modèle","La distance entre classes","La taille du dataset"], ans:0},
        {q:"Qu'est-ce que l'error analysis ?", opts:["Analyser erreurs pour améliorer modèle","Mesurer la loss sur train","Faire du clustering sur erreurs","Rien"], ans:0},
        {q:"Quel algorithme est binaire par nature mais utilisable en multiclass via one-vs-rest ?", opts:["Logistic Regression","KMeans","PCA","DBSCAN"], ans:0}
      ]},

      {id:4, title:'Training Models', desc:'10 questions', qs:[
        {q:"Quel est le principe de la Normal Equation ?", opts:["Trouver θ en inversant X^T X","Utiliser uniquement SGD","Toujours utiliser SVD","Calculer la cross entropy"], ans:0},
        {q:"Pourquoi la pseudoinverse SVD est préférée à l'inversion directe ?", opts:["Toujours plus rapide","Toujours plus précise","Toujours définie même si matrice non inversible","Évite la régularisation"], ans:2},
        {q:"Le gradient d'une fonction représente :", opts:["La vitesse de convergence","La direction de la plus forte diminution","La variation locale","La distance à la solution"], ans:1},
        {q:"Quel paramètre contrôle l'amplitude de mise à jour dans Gradient Descent ?", opts:["Batch size","Learning rate","Momentum","Nombre d'itérations"], ans:1},
        {q:"Un learning rate trop élevé provoque :", opts:["Une convergence rapide","Une divergence ou oscillation","Un overfitting","Une descente monotone"], ans:1},
        {q:"Avantage principal du Batch GD :", opts:["Très stable","Instantané","Pas besoin de matrices","Très peu de mémoire"], ans:0},
        {q:"Pourquoi Mini-Batch GD est souvent préféré ?", opts:["Moins cher en calcul","Régularisation + rapidité","Élimine oscillations","Indépendant du LR"], ans:1},
        {q:"Critère standard d'arrêt du GD ?", opts:["Nombre d'itérations","Norme du gradient ≈ 0","Accuracy","Heuristique seulement"], ans:1},
        {q:"Quel algorithme minimise la fonction de coût via dérivée ?", opts:["Gradient Descent","K-Means","PCA","Decision Tree"], ans:0},
        {q:"La différence entre SGD et Batch GD :", opts:["SGD utilise un seul exemple par mise à jour","Batch GD utilise tout le dataset","Les deux","SGD utilise GPU uniquement"], ans:0},
        {q:"Pourquoi utiliser regularization ?", opts:["Pour évitez l'overfitting","Pour accélérer l'entraînement","Pour augmenter le nombre de features","Pour visualiser"], ans:0},
        {q:"Ridge regression utilise :", opts:["L1 regularization","L2 regularization","Dropout","Softmax"], ans:1},
        {q:"Lasso peut faire :", opts:["Sélectionner des features (sparse)","Augmenter overfitting","Transformer en clustering","Calculer PCA"], ans:0},
        {q:"Early stopping sert à :", opts:["Arrêter l'entraînement pour éviter overfitting","Augmenter le learning rate","Tester le modèle","Faire du hyperparameter tuning"], ans:0},
        {q:"Softmax regression est :", opts:["Une régression pour variables continues","Un modèle pour classification multiclasse","Un algorithme de clustering","Une méthode de preprocessing"], ans:1},
        {q:"Polynomial regression permet :", opts:["Modéliser relations non-linéaires","Réduire le dataset","Faire PCA","Clustering"], ans:0},
        {q:"Que montrent les learning curves ?", opts:["Performance en fonction de la taille du training set","La distribution des features","Les coefficients du modèle","La confusion matrix"], ans:0},
        {q:"Quel est un avantage de mini-batch gradient descent ?", opts:["Convergence plus stable et parallélisable","Toujours plus rapide que SGD","Pas besoin de normaliser","Rend le modèle linéaire"], ans:0}
      ]},

      {id:5, title:'Support Vector Machines', desc:'8 questions', qs:[
        {q:"Le but d'un SVM linéaire est :", opts:["Trouver une frontière séparatrice avec marge maximale","Faire du clustering","Estimer densité","Réduire dimension"], ans:0},
        {q:"Soft margin permet :", opts:["Tolérer quelques erreurs pour mieux généraliser","Empêcher toute erreur","Rendre le modèle non-linéaire","Augmenter le nombre de features"], ans:0},
        {q:"Kernel RBF permet :", opts:["Séparer des données non-linéaires","Accélérer SGD","Faire PCA","Clustering hiérarchique"], ans:0},
        {q:"Le paramètre C contrôle :", opts:["Le trade-off entre marge et erreurs d'entraînement","Le learning rate","La taille du dataset","Le nombre de classes"], ans:0},
        {q:"Ajouter des features de similarité peut aider :", opts:["SVM à capturer non-linéarités","PCA à converger","KMeans à trouver k","Rien"], ans:0},
        {q:"Quel est un inconvénient des SVM ?", opts:["Complexité computationnelle pour grands datasets","Ils ne fonctionnent pas en classification","Toujours surfit","Ils demandent GPU"], ans:0},
        {q:"Un kernel polynomial introduit :", opts:["Features non-linéaires via polynômes","Régularisation L1","Dropout","Feature scaling automatique"], ans:0},
        {q:"SVM est principalement utilisé pour :", opts:["Classification (et parfois régression)","Clustering","Génération de données","Visualisation"], ans:0}
      ]},

      {id:6, title:'Decision Trees and Random Forests', desc:'10 questions', qs:[
        {q:"Un avantage des arbres de décision :", opts:["Interprétables","Toujours linéaires","Nécessitent peu de données","Jamais overfit"], ans:0},
        {q:"Pruning sert à :", opts:["Réduire overfitting","Augmenter profondeur","Faire plus de features","Rien"], ans:0},
        {q:"Random Forest combine :", opts:["Plusieurs arbres pour réduire variance","Des SVM","PCA avec KMeans","Un seul arbre profond"], ans:0},
        {q:"Bootstrap dans Random Forest signifie :", opts:["Échantillonnage avec replacement","Échantillonnage sans replacement","Mélanger features","Faire PCA"], ans:0},
        {q:"Feature importance dans Random Forest :", opts:["Estimation de l'impact des features","Une métrique de clustering","La profondeur moyenne","Un hyperparamètre"], ans:0},
        {q:"Un inconvénient des arbres :", opts:["Très sensibles au bruit","Toujours lents","Impossible à implémenter","Toujours interprétables"], ans:0},
        {q:"Généralement, Random Forest améliore :", opts:["La variance (stabilité)","Le biais uniquement","La mémoire utilisée","La vitesse d'entraînement"], ans:0},
        {q:"OOB (out-of-bag) permet :", opts:["Évaluer sans test set séparé","Augmenter la profondeur","Rendre les arbres plus simples","Faire cross-validation"], ans:0},
        {q:"Le paramètre max_features contrôle :", opts:["Nombre de features considérées à chaque split","La profondeur maximale","La taille du dataset","Le learning rate"], ans:0},
        {q:"Les arbres gèrent bien :", opts:["Données mixtes numériques et catégoriques","Seulement données numériques","Seulement images","Seulement séries temporelles"], ans:0}
      ]},

      {id:7, title:'Neural Networks', desc:'10 questions', qs:[
        {q:"Une couche dense (fully connected) :", opts:["Connecte chaque neurone à tous les précédents","Est utilisée uniquement pour images","Est un algorithme non paramétrique","Réduit toujours le sur-apprentissage"], ans:0},
        {q:"Activation ReLU sert à :", opts:["Introduire la non-linéarité","Faire PCA","Régulariser","Normaliser les données"], ans:0},
        {q:"La fonction de perte cross-entropy est adaptée pour :", opts:["Classification probabiliste","Régression continue","Clustering","PCA"], ans:0},
        {q:"Batch normalization aide à :", opts:["Stabiliser et accélérer l'entraînement","Augmenter le dataset","Faire plus de features","Clustering"], ans:0},
        {q:"Dropout sert à :", opts:["Réduire l'overfitting en désactivant aléatoirement des neurones","Augmenter la profondeur","Faire feature selection","Optimiser le GPU"], ans:0},
        {q:"Un autoencoder est utilisé pour :", opts:["Réduction de dimension / compression","Classification multiclass","Clustering hiérarchique","SVM"], ans:0},
        {q:"Le learning rate trop grand provoque :", opts:["Divergence de l'entraînement","Convergence plus rapide et stable","Toujours meilleur généralisation","Rien"], ans:0},
        {q:"Epoch signifie :", opts:["Un passage complet sur le dataset","Un type d'activation","Une métrique","Un hyperparamètre qui regularise"], ans:0},
        {q:"Vanishing gradient signifie :", opts:["Le gradient devient très petit dans les couches profondes","Le dataset est trop petit","Le modèle overfit","La précision chute"], ans:0},
        {q:"Une architecture CNN est particulièrement adaptée pour :", opts:["Données structurées spatiales (images)","Données tabulaires","Séries temporelles seulement","Clustering"], ans:0}
      ]},

      {id:8, title:'Dimensionality Reduction', desc:'8 questions', qs:[
        {q:"La curse of dimensionality signifie que :", opts:["Données compactes","Distances non fiables","Clustering plus facile","Bruit disparaît"], ans:1},
        {q:"La réduction par projection consiste à :", opts:["Augmenter les features","Projeter sur un espace réduit","Créer clusters","Normaliser"], ans:1},
        {q:"Pourquoi la réduction de dimension aide ?", opts:["Accélère + généralise","Ajoute bruit","Perd corrélation","Complexifie"], ans:0},
        {q:"Avantage du PCA :", opts:["Non linéaire","Maximise la variance","Crée clusters","Utilise labels"], ans:1},
        {q:"Une représentation des données peut être :", opts:["Axe orthogonal","Manifold de faible dimension","Matrice aléatoire","Fonction convexe"], ans:1},
        {q:"Objectif global de la réduction de dimension :", opts:["Garder info essentielle","Augmenter variance","Densifier","Créer clusters"], ans:0},
        {q:"PCA vise à :", opts:["Projeter les données sur axes de plus grande variance","Clustering","Générer labels","Régulariser modèles"], ans:0},
        {q:"t-SNE est utilisé pour :", opts:["Visualisation 2D/3D (préservation voisinage)","Entraîner modèles plus rapides","Régler hyperparamètres","Augmenter features"], ans:0},
        {q:"Kernel PCA permet :", opts:["Capturer non-linéarités via noyau","Faire cross-validation","Augmenter variance","Normaliser"], ans:0},
        {q:"Explained variance ratio indique :", opts:["Proportion de variance expliquée par composante","La loss","La profondeur du modèle","Le nombre de clusters"], ans:0},
        {q:"Réduction de dimension peut aider :", opts:["Accélérer entraînement et réduire bruit","Toujours augmenter accuracy","Rendre les données non-linéaires","Empêcher overfitting systématiquement"], ans:0},
        {q:"Une limite de t-SNE :", opts:["Coûteux pour grands datasets","Toujours linéaire","Impossible à visualiser","Ne fonctionne qu'avec images"], ans:0},
        {q:"LLE (Locally Linear Embedding) est une méthode de :", opts:["Manifold learning","Ridge regression","Dropout","Clustering"], ans:0},
        {q:"PCA est sensible à :", opts:["Scale des features","Le format du fichier","Le nombre de classes","La couleur des plots"], ans:0}
      ]},

      {id:9, title:'Unsupervised Learning Techniques', desc:'10 questions', qs:[
        {q:"K-Means nécessite de spécifier :", opts:["Le nombre de clusters k","Le learning rate","Le kernel","La profondeur"], ans:0},
        {q:"DBSCAN détecte clusters en fonction de :", opts:["Densité (eps, min_samples)","Variance","Learning rate","Nombre d'arbres"], ans:0},
        {q:"Gaussian Mixture Models servent à :", opts:["Estimer densité et clusterer via distributions gaussiennes","Faire PCA","Classer images","Optimiser SVM"], ans:0},
        {q:"Isolation Forest est destiné à :", opts:["Détection d'anomalies","Classification","Régression","Visualisation"], ans:0},
        {q:"Clustering hiérarchique produit :", opts:["Dendrogramme","Matrice de confusion","ROC curve","Explained variance"], ans:0},
        {q:"Silhouette score mesure :", opts:["Qualité des clusters (cohésion/séparation)","La variance expliquée","La loss","Le recall"], ans:0},
        {q:"Semi-supervised learning combine :", opts:["Un peu de labels + beaucoup d'unlabeled","Seulement supervision","Reinforcement et supervised","PCA et SVM"], ans:0},
        {q:"Clustering peut servir pour :", opts:["Prétraitement, segmentation, détection d'anomalies","Augmenter hyperparamètres","Evaluer précision","Faire cross-validation"], ans:0},
        {q:"La réduction de dimension peut aider K-Means en :", opts:["Réduisant le bruit et accélérant le clustering","Augmentant k automatiquement","Remplaçant l'algorithme","Rien"], ans:0},
        {q:"La density estimation permet :", opts:["Déterminer régions à faible densité (anomalies)","Augmenter la profondeur du modèle","Visualiser couches de réseau","Sélectionner features"], ans:0}
      ]}
    ];

    // build chapter list
    const chapListEl = document.getElementById('chapList');
    chapters.forEach((c,i)=>{
      const el = document.createElement('div');
      el.className = 'chap' + (i===0? ' active':'');
      el.dataset.idx = i;
      el.innerHTML = `<strong>Chapitre ${c.id}.</strong> ${c.title} <div class="muted">${c.desc}</div>`;
      el.addEventListener('click', ()=>{ selectChapter(i); document.querySelectorAll('.chap').forEach(n=>n.classList.remove('active')); el.classList.add('active'); });
      chapListEl.appendChild(el);
    });

    const titleEl = document.getElementById('title');
    const subtitleEl = document.getElementById('subtitle');
    const quizEl = document.getElementById('quiz');
    const progressEl = document.getElementById('progress');
    const globalProgressEl = document.getElementById('globalProgress');
    const resultsEl = document.getElementById('results');

    let current = 0;

    function selectChapter(idx){
      current = idx;
      const ch = chapters[idx];
      titleEl.innerText = `Chapitre ${ch.id} — ${ch.title}`;
      subtitleEl.innerText = ch.desc + ' — ' + ch.qs.length + ' questions';
      renderChapter(ch);
      updateGlobalProgress();
      resultsEl.style.display='none';
      window.scrollTo({top:0,behavior:'smooth'});
    }

    function renderChapter(ch){
      quizEl.innerHTML = '';
      ch.qs.forEach((qs, qi)=>{
        const div = document.createElement('div'); div.className='q';
        const h = document.createElement('h3'); h.innerText = (qi+1)+'. '+qs.q; div.appendChild(h);
        const alts = document.createElement('div'); alts.className='alts';
        qs.opts.forEach((opt,oi)=>{
          const label = document.createElement('label'); label.className='alt'; label.htmlFor = `c${ch.id}_q${qi}_opt${oi}`;
          const input = document.createElement('input'); input.type='radio'; input.name=`c${ch.id}_q${qi}`; input.id=`c${ch.id}_q${qi}_opt${oi}`; input.value=oi;
          input.addEventListener('change', updateProgress);
          const span = document.createElement('span'); span.innerText = String.fromCharCode(65+oi)+') '+opt;
          label.appendChild(input); label.appendChild(span); alts.appendChild(label);
        });
        div.appendChild(alts); quizEl.appendChild(div);
      });
      updateProgress();
    }

    function updateProgress(){
      const ch = chapters[current];
      const answered = ch.qs.filter((_,i)=> !!document.querySelector(`input[name='c${ch.id}_q${i}']:checked`)).length;
      progressEl.innerText = answered + ' / ' + ch.qs.length;
      updateGlobalProgress();
    }

    function updateGlobalProgress(){
      let total=0, answered=0;
      chapters.forEach((ch,ci)=>{
        total += ch.qs.length;
        ch.qs.forEach((_,i)=>{ if(document.querySelector(`input[name='c${ch.id}_q${i}']:checked`)) answered++; });
      });
      globalProgressEl.innerText = answered + ' / ' + total;
    }

    function checkChapter(){
      const ch = chapters[current];
      let score=0;
      ch.qs.forEach((q,i)=>{
        const sel = document.querySelector(`input[name='c${ch.id}_q${i}']:checked`);
        const user = sel ? parseInt(sel.value): null;
        const correct = q.ans;
        const qdiv = quizEl.children[i];
        qdiv.querySelectorAll('.alt').forEach(l=>{ l.style.borderColor='transparent'; l.style.opacity='1'; });
        if(user === correct){ score++; if(user!==null) qdiv.querySelectorAll('.alt')[user].style.borderColor='rgba(0,255,160,0.2)'; }
        else { if(user!==null) qdiv.querySelectorAll('.alt')[user].style.borderColor='rgba(255,100,110,0.12)'; qdiv.querySelectorAll('.alt')[correct].style.borderColor='rgba(0,255,160,0.2)'; }
      });
      resultsEl.style.display='block'; resultsEl.innerHTML = `<strong>Score chapitre ${ch.id} : ${score} / ${ch.qs.length}</strong><div style="margin-top:8px;color:var(--muted)">Taux: ${Math.round(score/ch.qs.length*100)}%</div>`;
      resultsEl.scrollIntoView({behavior:'smooth',block:'nearest'});
      updateGlobalProgress();
    }

    function showAnswers(){
      const ch = chapters[current];
      ch.qs.forEach((q,i)=>{
        const qdiv = quizEl.children[i];
        qdiv.querySelectorAll('.alt').forEach((label,idx)=>{ label.style.opacity = (idx===q.ans? '1':'0.45'); label.style.borderColor = (idx===q.ans? 'rgba(0,255,160,0.2)':'transparent'); });
      });
      resultsEl.style.display='block'; resultsEl.innerHTML = `<strong>Réponses affichées — Chapitre ${ch.id}</strong>`;
      resultsEl.scrollIntoView({behavior:'smooth',block:'nearest'});
    }

    function resetChapter(){
      const ch = chapters[current];
      ch.qs.forEach((_,i)=>{ document.querySelectorAll(`input[name='c${ch.id}_q${i}']`).forEach(n=>n.checked=false); });
      document.querySelectorAll('.alt').forEach(l=>{ l.style.borderColor='transparent'; l.style.opacity='1'; });
      resultsEl.style.display='none';
      updateProgress();
    }

    function checkAllChapters(){
      // iterate chapters and compute cumulative score
      let tot=0,sc=0;
      chapters.forEach((ch)=>{ ch.qs.forEach((q,i)=>{ tot++; const sel = document.querySelector(`input[name='c${ch.id}_q${i}']:checked`); const user = sel?parseInt(sel.value):null; if(user===q.ans) sc++; }); });
      resultsEl.style.display='block'; resultsEl.innerHTML = `<strong>Score global : ${sc} / ${tot}</strong><div style="margin-top:8px;color:var(--muted)">Taux: ${Math.round(sc/tot*100)}%</div>`;
      resultsEl.scrollIntoView({behavior:'smooth',block:'nearest'});
      updateGlobalProgress();
    }

    function resetAll(){
      document.querySelectorAll('input[type=radio]').forEach(i=>i.checked=false);
      document.querySelectorAll('.alt').forEach(l=>{ l.style.borderColor='transparent'; l.style.opacity='1'; });
      resultsEl.style.display='none';
      updateProgress();
    }

    // wire up buttons
    document.getElementById('check').addEventListener('click', checkChapter);
    document.getElementById('showAnswers').addEventListener('click', showAnswers);
    document.getElementById('reset').addEventListener('click', resetChapter);
    document.getElementById('checkAll').addEventListener('click', checkAllChapters);
    document.getElementById('resetAll').addEventListener('click', resetAll);

    // init
    selectChapter(0);
  </script>
</body>
</html>
